{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Build basic ML Model without Tensorflow (followed tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Relevent Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Random Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the inputs are: \n",
      "[[ -2.44598754  -7.38272624]\n",
      " [-10.58523912  -2.89154484]\n",
      " [ -5.38626623   5.31510214]\n",
      " [ -0.36003119 -10.80334177]\n",
      " [  9.16743226   5.07262853]\n",
      " [  9.84885506  -7.90901709]\n",
      " [  1.60641678   9.22216383]\n",
      " [ -6.65536833  -8.00472393]\n",
      " [ -1.88236989  10.80488485]\n",
      " [-14.19741252   8.50859908]\n",
      " [-10.13687684  -5.78654343]\n",
      " [  9.78177156   1.35480547]\n",
      " [  2.19173243 -14.80779795]\n",
      " [ -6.7440126    6.24977359]\n",
      " [  0.59005441   9.98398628]\n",
      " [ -9.3510186   -6.04205493]\n",
      " [  6.61067462   1.51147486]\n",
      " [-12.76797166  -4.55190192]\n",
      " [ 10.36149303  -3.16860011]\n",
      " [  2.94503686  13.14989384]\n",
      " [ -8.50294135  14.11223216]\n",
      " [ -9.9341626  -10.79288065]\n",
      " [-11.60834559   2.57128354]\n",
      " [ -6.53413452  -1.59094456]\n",
      " [ 11.26030319 -12.7961754 ]\n",
      " [  7.65396335  11.5783453 ]\n",
      " [  5.50215186  -9.67096519]\n",
      " [  7.70312246  10.2648659 ]\n",
      " [ -5.74066654 -12.73250044]\n",
      " [  6.82974092  -4.2436169 ]\n",
      " [ -5.72922168   1.1673098 ]\n",
      " [-10.97317276  -6.61998802]\n",
      " [  6.99788739  -3.7247935 ]\n",
      " [ -3.74385994  -1.63298855]\n",
      " [-13.964299     2.51326958]\n",
      " [  2.83721951  -1.54296308]\n",
      " [ -0.44039684  -1.19225589]\n",
      " [ -9.57346385  -6.21910508]\n",
      " [  1.81512316   2.98896031]\n",
      " [ -9.42137609   8.91330426]\n",
      " [ -2.13328938 -14.48539614]\n",
      " [ 14.13736465  14.46627708]\n",
      " [  0.2627291    0.60776361]\n",
      " [ -2.66354892  12.07060646]\n",
      " [ -0.98681595  12.58185519]\n",
      " [  0.39954834   9.68842813]\n",
      " [  2.82189773   1.86678875]\n",
      " [  7.11019351  -5.8772688 ]\n",
      " [ -5.52406382  -0.86806775]\n",
      " [  7.58969794  -0.09611892]\n",
      " [ -8.67746512  -4.85554787]\n",
      " [ -5.55211891  -7.07469371]\n",
      " [ -6.40299642 -12.34595828]\n",
      " [  4.99760588  -7.63999356]\n",
      " [  6.03552555  12.71844324]\n",
      " [  1.74487693  -1.97051742]\n",
      " [ -1.29847516  11.5668909 ]\n",
      " [ 14.11777758   9.93188729]\n",
      " [ 14.86103834   1.46769289]\n",
      " [  7.51282048  -0.12575904]\n",
      " [ -9.12041437 -13.53627547]\n",
      " [ 10.89640919   8.76743725]\n",
      " [-11.06492012  -4.4559366 ]\n",
      " [ -4.99568608  -8.39666381]\n",
      " [ -3.94276642  10.83182571]\n",
      " [  1.51611928  -5.13234479]\n",
      " [ -5.63167167   1.08459892]\n",
      " [-11.71859081   4.58994544]\n",
      " [-12.4969337  -14.4639248 ]\n",
      " [  8.45115627  14.62726734]\n",
      " [  0.40556857   6.33585731]\n",
      " [-13.46258434  -6.44672618]\n",
      " [  5.6179821  -13.5272514 ]\n",
      " [  1.73152559  -7.46690814]\n",
      " [-13.73647361  -9.77737559]\n",
      " [ -1.43353034  13.58928013]\n",
      " [-13.41625754  -2.55919374]\n",
      " [-11.83338944   6.30633557]\n",
      " [  8.15076297  -7.33232764]\n",
      " [ -8.53034968 -10.23413648]\n",
      " [ -8.67695848  -3.57512513]\n",
      " [-14.79644194 -14.54378916]\n",
      " [-14.72661288   1.26016447]\n",
      " [ 10.00004813   4.38047957]\n",
      " [-11.62258379  -3.67805161]\n",
      " [ 13.12800018   2.16195584]\n",
      " [  0.3548569    0.74750613]\n",
      " [ 10.81793106 -13.78618419]\n",
      " [  0.80790513  -8.61586143]\n",
      " [ -8.91332623   7.2477082 ]\n",
      " [  9.63656845   4.77275767]\n",
      " [ -1.75139203  -1.64452944]\n",
      " [ -8.18577524  13.7569943 ]\n",
      " [ -6.42662107  -8.15043633]\n",
      " [ -7.27759805   4.05379218]\n",
      " [ 12.22112653  -8.19431122]\n",
      " [ -3.96073019 -14.89417238]\n",
      " [ -1.66787765   6.33246699]\n",
      " [ -1.11027712  -9.1165983 ]\n",
      " [ -4.1387141    9.91055003]\n",
      " [ -3.30667809 -10.04371126]\n",
      " [ -3.46101731 -11.14343446]\n",
      " [ -7.41511545 -11.57685626]\n",
      " [ -6.81879701  -3.94246989]\n",
      " [  1.75911732  -9.7680294 ]\n",
      " [  6.62700195 -10.20823109]\n",
      " [  5.09969699 -10.55256308]\n",
      " [ -7.43960631   8.60849677]\n",
      " [ -0.36849491   4.86958768]\n",
      " [  1.60047051  11.89541038]\n",
      " [ -9.39203084 -12.52892539]\n",
      " [-12.4645341   -5.96186865]\n",
      " [ -0.64260156  -4.41870184]\n",
      " [ -7.47777241  -6.06886644]\n",
      " [  3.7164809    7.17554725]\n",
      " [  2.5787744    8.21239096]\n",
      " [ -1.29177015  -8.35865816]\n",
      " [ -6.94410654  -4.51090446]]\n",
      "(118, 2)\n"
     ]
    }
   ],
   "source": [
    "obs = 118\n",
    "xs = np.random.uniform(low=-15,high=15,size=(obs, 1))\n",
    "zs = np.random.uniform(-15, 15, (obs, 1))\n",
    "inputs = np.column_stack((xs, zs))\n",
    "print (\"the inputs are: \\n\" + str(inputs))\n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Noise / Targets & Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the targets is (118, 1)\n",
      "[[-0.10114592]\n",
      " [ 0.05230368]]\n",
      "[-0.1313693]\n"
     ]
    }
   ],
   "source": [
    "# create targets \n",
    "noise = np.random.uniform(-2,2,(obs, 1)) \n",
    "\n",
    "X_CONSTANT = 5\n",
    "Z_CONSTANT = -3\n",
    "targets = X_CONSTANT*xs + Z_CONSTANT*zs + noise\n",
    "print (\"the shape of the targets is \" + str(targets.shape))\n",
    "\n",
    "# intialize variables\n",
    "\n",
    "init_range = 0.2\n",
    "weights = np.random.uniform(-init_range, init_range, size = (2,1))\n",
    "biases = np.random.uniform(-init_range, init_range, size=1)\n",
    "\n",
    "print (weights)\n",
    "print (biases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual weight: 5, calculated weight: 5.016515527871507\n",
      "actual weight: -3, calculated weight: -2.997205394960963\n"
     ]
    }
   ],
   "source": [
    "# set learning rate\n",
    "learning_rate = 0.02\n",
    "\n",
    "# train the model\n",
    "for i in range (500):\n",
    "    \n",
    "    # calcualte the projected outputs and difference from expectation\n",
    "    outputs = np.dot(inputs,weights) + biases\n",
    "    diff = outputs - targets\n",
    "    \n",
    "    # instead of mean_squared_error, I am going to do MAD - mean absolute deviation\n",
    "    loss = np.sum(abs(diff)) / obs\n",
    "    \n",
    "    diff_scaled = diff / obs\n",
    "    weights -= learning_rate * np.dot(inputs.T, diff_scaled)\n",
    "    biases -= learning_rate * np.sum(diff_scaled)\n",
    "    \n",
    "print (\"actual weight: 5, calculated weight: \" + str(float(weights[0])))\n",
    "print (\"actual weight: -3, calculated weight: \" + str(float(weights[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 28.8610\n",
      "Epoch 2/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2063\n",
      "Epoch 3/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1726\n",
      "Epoch 4/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1777\n",
      "Epoch 5/25\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1762\n",
      "Epoch 6/25\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1779\n",
      "Epoch 7/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1786\n",
      "Epoch 8/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1799\n",
      "Epoch 9/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1783\n",
      "Epoch 10/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1757\n",
      "Epoch 11/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 12/25\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1739\n",
      "Epoch 13/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1770\n",
      "Epoch 14/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1785\n",
      "Epoch 15/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1757\n",
      "Epoch 16/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1760\n",
      "Epoch 17/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1787\n",
      "Epoch 18/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1776\n",
      "Epoch 19/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1769\n",
      "Epoch 20/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1747\n",
      "Epoch 21/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1738\n",
      "Epoch 22/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1778\n",
      "Epoch 23/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1796\n",
      "Epoch 24/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1768\n",
      "Epoch 25/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1740\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "obs = 10000\n",
    "xs = np.random.uniform(low=-8,high=8,size=(obs, 1))\n",
    "zs = np.random.uniform(-12, 12, (obs, 1))\n",
    "generated_inputs = np.column_stack(((xs,zs)))\n",
    "\n",
    "\n",
    "generated_targets = 12*xs - 6*zs\n",
    "\n",
    "np.savez(\"TF_intro\", inputs=generated_inputs, targets=generated_targets)\n",
    "\n",
    "training_data = np.load(\"TF_intro.npz\")\n",
    "\n",
    "# unlike other packages, when employing tf we must actually build the model\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1,kernel_initializer = 'zeros', bias_initializer = 'zeros')])\n",
    "\n",
    "# my loss function\n",
    "def my_loss_fn(y_true, y_pred):\n",
    "    absolute_diff = tf.math.abs(y_true - y_pred)\n",
    "    return absolute_diff\n",
    "\n",
    "\n",
    "model.compile(loss=my_loss_fn, optimizer='sgd')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=25)\n",
    "\n",
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data[\"targets\"]))\n",
    "\n",
    "plt.xlabel('inputs')\n",
    "plt.ylabel('outputs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Working on Audiobooks_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: code below comes from a Udemy tutorial... I did however write it all up and comment myself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load, balance, and shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing again...\n",
    "import numpy as np\n",
    "from sklearn import preprocessing # helpful to clean up data\n",
    "\n",
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1] #get all columns besides the first (customer ID) and last one\n",
    "targets_all = raw_csv_data[:, -1] # the target (outcome) is the last column\n",
    "\n",
    "# need to get an equal amount of 0 and 1s (balanced dataset)\n",
    "\n",
    "num_one_targets = int(np.sum(targets_all)) # number of ones\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "numtargets = targets_all.shape[0]\n",
    "\n",
    "for i in range(numtargets):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets: \n",
    "            indices_to_remove.append(i) # removal enables balance\n",
    "\n",
    "# these new variables are the same as above but with removed indices\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)\n",
    "\n",
    "# standardize & shuffle data\n",
    "\n",
    "# standardize inputs\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)\n",
    "\n",
    "# shuffle data - it was originally arranged by date, which could be a confounding factor\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split dataset into test, train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# constants to fiddle around with\n",
    "percent_train = 0.8\n",
    "percent_test = 0.1\n",
    "\n",
    "train_samples_count = int(percent_train * samples_count)\n",
    "test_samples_count = int(percent_test * samples_count)\n",
    "validation_samples_count = samples_count - train_samples_count - test_samples_count\n",
    "\n",
    "# this gets the first x of each input/target to be train, next to be test, last to be validation\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count:train_samples_count+test_samples_count]\n",
    "test_targets = shuffled_targets[train_samples_count:train_samples_count+test_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count+test_samples_count:]\n",
    "validation_targets = shuffled_targets[train_samples_count+test_samples_count:]\n",
    "\n",
    "# Save up the train, validation, and test as npzs\n",
    "np.savez(\"Audiobooks_data_train\", inputs=train_inputs, targets=train_targets)\n",
    "np.savez(\"Audiobooks_data_test\", inputs=test_inputs, targets=test_targets)\n",
    "np.savez(\"Audiobooks_data_validation\", inputs=validation_inputs, targets=validation_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load in npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load(\"Audiobooks_data_train.npz\")\n",
    "train_inputs = npz[\"inputs\"].astype(np.float)\n",
    "train_targets = npz[\"targets\"].astype(np.int) # since the outcome is 0 or 1\n",
    "\n",
    "npz = np.load(\"Audiobooks_data_validation.npz\")\n",
    "validation_inputs = npz[\"inputs\"].astype(np.float)\n",
    "validation_targets = npz[\"targets\"].astype(np.int)\n",
    "\n",
    "npz = np.load(\"Audiobooks_data_test.npz\")\n",
    "test_inputs = npz[\"inputs\"].astype(np.float)\n",
    "test_targets = npz[\"targets\"].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 20\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='elu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='elu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='elu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.4770 - accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3426 - accuracy: 0.8773\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3112 - accuracy: 0.8860\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.2976 - accuracy: 0.8919\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2875 - accuracy: 0.8935\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2814 - accuracy: 0.8947\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2757 - accuracy: 0.8949\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2700 - accuracy: 0.8963\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2658 - accuracy: 0.8986\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2633 - accuracy: 0.8972\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2601 - accuracy: 0.9011\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2576 - accuracy: 0.9011\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2561 - accuracy: 0.9019\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2561 - accuracy: 0.9028\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2531 - accuracy: 0.9028\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2544 - accuracy: 0.9028\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2508 - accuracy: 0.9033\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2496 - accuracy: 0.9047\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2478 - accuracy: 0.9064\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.2483 - accuracy: 0.9078\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.2446 - accuracy: 0.9064\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.2435 - accuracy: 0.9070\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.2419 - accuracy: 0.9081\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.2415 - accuracy: 0.9067\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.2424 - accuracy: 0.9078\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.2425 - accuracy: 0.9072\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.2396 - accuracy: 0.9072\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.2376 - accuracy: 0.9081\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.2393 - accuracy: 0.9086\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.2392 - accuracy: 0.9100\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.2366 - accuracy: 0.9095\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.2393 - accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "36/36 - 0s - loss: 0.2360 - accuracy: 0.9092\n",
      "Epoch 34/100\n",
      "36/36 - 0s - loss: 0.2367 - accuracy: 0.9109\n",
      "Epoch 35/100\n",
      "36/36 - 0s - loss: 0.2351 - accuracy: 0.9103\n",
      "Epoch 36/100\n",
      "36/36 - 0s - loss: 0.2369 - accuracy: 0.9078\n",
      "Epoch 37/100\n",
      "36/36 - 0s - loss: 0.2355 - accuracy: 0.9103\n",
      "Epoch 38/100\n",
      "36/36 - 0s - loss: 0.2352 - accuracy: 0.9106\n",
      "Epoch 39/100\n",
      "36/36 - 0s - loss: 0.2368 - accuracy: 0.9095\n",
      "Epoch 40/100\n",
      "36/36 - 0s - loss: 0.2324 - accuracy: 0.9106\n",
      "Epoch 41/100\n",
      "36/36 - 0s - loss: 0.2359 - accuracy: 0.9098\n",
      "Epoch 42/100\n",
      "36/36 - 0s - loss: 0.2348 - accuracy: 0.9106\n",
      "Epoch 43/100\n",
      "36/36 - 0s - loss: 0.2350 - accuracy: 0.9106\n",
      "Epoch 44/100\n",
      "36/36 - 0s - loss: 0.2326 - accuracy: 0.9123\n",
      "Epoch 45/100\n",
      "36/36 - 0s - loss: 0.2331 - accuracy: 0.9092\n",
      "Epoch 46/100\n",
      "36/36 - 0s - loss: 0.2344 - accuracy: 0.9111\n",
      "Epoch 47/100\n",
      "36/36 - 0s - loss: 0.2348 - accuracy: 0.9095\n",
      "Epoch 48/100\n",
      "36/36 - 0s - loss: 0.2319 - accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "36/36 - 0s - loss: 0.2316 - accuracy: 0.9128\n",
      "Epoch 50/100\n",
      "36/36 - 0s - loss: 0.2321 - accuracy: 0.9134\n",
      "Epoch 51/100\n",
      "36/36 - 0s - loss: 0.2309 - accuracy: 0.9098\n",
      "Epoch 52/100\n",
      "36/36 - 0s - loss: 0.2303 - accuracy: 0.9109\n",
      "Epoch 53/100\n",
      "36/36 - 0s - loss: 0.2330 - accuracy: 0.9123\n",
      "Epoch 54/100\n",
      "36/36 - 0s - loss: 0.2284 - accuracy: 0.9134\n",
      "Epoch 55/100\n",
      "36/36 - 0s - loss: 0.2276 - accuracy: 0.9145\n",
      "Epoch 56/100\n",
      "36/36 - 0s - loss: 0.2303 - accuracy: 0.9123\n",
      "Epoch 57/100\n",
      "36/36 - 0s - loss: 0.2280 - accuracy: 0.9125\n",
      "Epoch 58/100\n",
      "36/36 - 0s - loss: 0.2279 - accuracy: 0.9128\n",
      "Epoch 59/100\n",
      "36/36 - 0s - loss: 0.2293 - accuracy: 0.9148\n",
      "Epoch 60/100\n",
      "36/36 - 0s - loss: 0.2271 - accuracy: 0.9114\n",
      "Epoch 61/100\n",
      "36/36 - 0s - loss: 0.2297 - accuracy: 0.9139\n",
      "Epoch 62/100\n",
      "36/36 - 0s - loss: 0.2275 - accuracy: 0.9123\n",
      "Epoch 63/100\n",
      "36/36 - 0s - loss: 0.2272 - accuracy: 0.9137\n",
      "Epoch 64/100\n",
      "36/36 - 0s - loss: 0.2274 - accuracy: 0.9153\n",
      "Epoch 65/100\n",
      "36/36 - 0s - loss: 0.2271 - accuracy: 0.9134\n",
      "Epoch 66/100\n",
      "36/36 - 0s - loss: 0.2275 - accuracy: 0.9151\n",
      "Epoch 67/100\n",
      "36/36 - 0s - loss: 0.2285 - accuracy: 0.9151\n",
      "Epoch 68/100\n",
      "36/36 - 0s - loss: 0.2270 - accuracy: 0.9153\n",
      "Epoch 69/100\n",
      "36/36 - 0s - loss: 0.2276 - accuracy: 0.9125\n",
      "Epoch 70/100\n",
      "36/36 - 0s - loss: 0.2274 - accuracy: 0.9159\n",
      "Epoch 71/100\n",
      "36/36 - 0s - loss: 0.2268 - accuracy: 0.9139\n",
      "Epoch 72/100\n",
      "36/36 - 0s - loss: 0.2280 - accuracy: 0.9134\n",
      "Epoch 73/100\n",
      "36/36 - 0s - loss: 0.2258 - accuracy: 0.9145\n",
      "Epoch 74/100\n",
      "36/36 - 0s - loss: 0.2257 - accuracy: 0.9142\n",
      "Epoch 75/100\n",
      "36/36 - 0s - loss: 0.2250 - accuracy: 0.9153\n",
      "Epoch 76/100\n",
      "36/36 - 0s - loss: 0.2253 - accuracy: 0.9120\n",
      "Epoch 77/100\n",
      "36/36 - 0s - loss: 0.2266 - accuracy: 0.9142\n",
      "Epoch 78/100\n",
      "36/36 - 0s - loss: 0.2280 - accuracy: 0.9151\n",
      "Epoch 79/100\n",
      "36/36 - 0s - loss: 0.2281 - accuracy: 0.9134\n",
      "Epoch 80/100\n",
      "36/36 - 0s - loss: 0.2253 - accuracy: 0.9131\n",
      "Epoch 81/100\n",
      "36/36 - 0s - loss: 0.2265 - accuracy: 0.9142\n",
      "Epoch 82/100\n",
      "36/36 - 0s - loss: 0.2238 - accuracy: 0.9137\n",
      "Epoch 83/100\n",
      "36/36 - 0s - loss: 0.2262 - accuracy: 0.9142\n",
      "Epoch 84/100\n",
      "36/36 - 0s - loss: 0.2236 - accuracy: 0.9148\n",
      "Epoch 85/100\n",
      "36/36 - 0s - loss: 0.2228 - accuracy: 0.9153\n",
      "Epoch 86/100\n",
      "36/36 - 0s - loss: 0.2256 - accuracy: 0.9151\n",
      "Epoch 87/100\n",
      "36/36 - 0s - loss: 0.2244 - accuracy: 0.9125\n",
      "Epoch 88/100\n",
      "36/36 - 0s - loss: 0.2225 - accuracy: 0.9151\n",
      "Epoch 89/100\n",
      "36/36 - 0s - loss: 0.2249 - accuracy: 0.9162\n",
      "Epoch 90/100\n",
      "36/36 - 0s - loss: 0.2227 - accuracy: 0.9159\n",
      "Epoch 91/100\n",
      "36/36 - 0s - loss: 0.2264 - accuracy: 0.9117\n",
      "Epoch 92/100\n",
      "36/36 - 0s - loss: 0.2277 - accuracy: 0.9131\n",
      "Epoch 93/100\n",
      "36/36 - 0s - loss: 0.2251 - accuracy: 0.9145\n",
      "Epoch 94/100\n",
      "36/36 - 0s - loss: 0.2225 - accuracy: 0.9145\n",
      "Epoch 95/100\n",
      "36/36 - 0s - loss: 0.2245 - accuracy: 0.9142\n",
      "Epoch 96/100\n",
      "36/36 - 0s - loss: 0.2226 - accuracy: 0.9153\n",
      "Epoch 97/100\n",
      "36/36 - 0s - loss: 0.2218 - accuracy: 0.9162\n",
      "Epoch 98/100\n",
      "36/36 - 0s - loss: 0.2248 - accuracy: 0.9145\n",
      "Epoch 99/100\n",
      "36/36 - 0s - loss: 0.2261 - accuracy: 0.9142\n",
      "Epoch 100/100\n",
      "36/36 - 0s - loss: 0.2251 - accuracy: 0.9156\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9351\n",
      "this is test loss: 0.20028327405452728\n",
      "this is test accuracy: 0.9351230263710022\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size = batch_size, \n",
    "          epochs = max_epochs, # number of iterations\n",
    "          verbose=2)\n",
    "\n",
    "# test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "\n",
    "print (\"this is test loss: \" + str(test_loss) + \"\\n\" + \"this is test accuracy: \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Working on MNIST (handwritten digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is the \"hello world\" of Machine Learning. It is a file of 70k handwritten digits, where each image is 28x28 pixels, and the input vale of each pixel is 0-255 where 0 is black and 255 is white.\n",
    "\n",
    "We will be running a deep neural network with 2 hidden layers, and 10 output units (0 to 9 is the answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import revelent libraries & split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# load data\n",
    "mnist_data, mnist_info = tfds.load(name=\"mnist\", with_info=True, as_supervised = True)\n",
    "# split\n",
    "mnist_train = mnist_data[\"train\"]\n",
    "mnist_test = mnist_data[\"test\"]\n",
    "\n",
    "# get validation\n",
    "VALIDATION_PERCENT = 0.1\n",
    "\n",
    "num_validation = VALIDATION_PERCENT * mnist_info.splits[\"train\"].num_examples\n",
    "num_validation = tf.cast(num_validation, tf.int64)\n",
    "num_test = mnist_info.splits[\"test\"].num_examples\n",
    "num_test = tf.cast(num_test, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return (image/255), label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shuffle and batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000 #dealing w/ enormous datasets, can't shuffle it all at once!\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation)\n",
    "test_data = test_data.batch(num_test)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outline and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 7s - loss: 0.4180 - accuracy: 0.8799 - val_loss: 0.2200 - val_accuracy: 0.9368\n",
      "Epoch 2/5\n",
      "540/540 - 4s - loss: 0.1921 - accuracy: 0.9437 - val_loss: 0.1701 - val_accuracy: 0.9502\n",
      "Epoch 3/5\n",
      "540/540 - 4s - loss: 0.1477 - accuracy: 0.9545 - val_loss: 0.1312 - val_accuracy: 0.9645\n",
      "Epoch 4/5\n",
      "540/540 - 3s - loss: 0.1226 - accuracy: 0.9633 - val_loss: 0.1366 - val_accuracy: 0.9607\n",
      "Epoch 5/5\n",
      "540/540 - 4s - loss: 0.1067 - accuracy: 0.9676 - val_loss: 0.1035 - val_accuracy: 0.9722\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9623\n"
     ]
    }
   ],
   "source": [
    "# Outline model\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 40\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "# choose optimizer and the loss function\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets), verbose=2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
