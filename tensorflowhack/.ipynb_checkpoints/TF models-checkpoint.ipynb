{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Build basic ML Model without Tensorflow (followed tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Relevent Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Random Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the inputs are: \n",
      "[[ -9.54798709   0.45091934]\n",
      " [  9.19814455   7.67138779]\n",
      " [-11.60646989  -8.66362331]\n",
      " ...\n",
      " [-11.36692313  14.62392188]\n",
      " [ -7.37037551  -9.25723794]\n",
      " [ 14.26254865  -3.44441904]]\n",
      "(1018, 2)\n"
     ]
    }
   ],
   "source": [
    "obs = 1018\n",
    "xs = np.random.uniform(low=-15,high=15,size=(obs, 1))\n",
    "zs = np.random.uniform(-15, 15, (obs, 1))\n",
    "inputs = np.column_stack((xs, zs))\n",
    "print (\"the inputs are: \\n\" + str(inputs))\n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Noise / Targets & Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the targets is (1018, 1)\n",
      "[[0.03059077]\n",
      " [0.01795597]]\n",
      "[0.15818072]\n"
     ]
    }
   ],
   "source": [
    "# create targets \n",
    "noise = np.random.uniform(-2,2,(obs, 1)) \n",
    "\n",
    "X_CONSTANT = 5\n",
    "Z_CONSTANT = -3\n",
    "targets = X_CONSTANT*xs + Z_CONSTANT*zs + noise\n",
    "print (\"the shape of the targets is \" + str(targets.shape))\n",
    "\n",
    "# intialize variables\n",
    "\n",
    "init_range = 0.2\n",
    "weights = np.random.uniform(-init_range, init_range, size = (2,1))\n",
    "biases = np.random.uniform(-init_range, init_range, size=1)\n",
    "\n",
    "print (weights)\n",
    "print (biases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual weight: 5, calculated weight: 4.995551349325371\n",
      "actual weight: -3, calculated weight: -3.0006439019802724\n"
     ]
    }
   ],
   "source": [
    "# set learning rate\n",
    "learning_rate = 0.02\n",
    "\n",
    "# train the model\n",
    "for i in range (500):\n",
    "    \n",
    "    # calculate the projected outputs and difference from expectation\n",
    "    outputs = np.dot(inputs,weights) + biases\n",
    "    diff = outputs - targets\n",
    "    \n",
    "    # I am going to do MAD - mean absolute deviation\n",
    "    loss = np.sum(abs(diff)) / obs\n",
    "    \n",
    "    diff_scaled = diff / obs\n",
    "    # apply changes to weights/biases\n",
    "    weights -= learning_rate * np.dot(inputs.T, diff_scaled)\n",
    "    biases -= learning_rate * np.sum(diff_scaled)\n",
    "    \n",
    "# show how model improves over time\n",
    "print (\"actual weight: 5, calculated weight: \" + str(float(weights[0])))\n",
    "print (\"actual weight: -3, calculated weight: \" + str(float(weights[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempting with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 28.8180\n",
      "Epoch 2/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2388A: 0s - loss: 0.34 - ETA: 0s - loss: 0\n",
      "Epoch 3/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1746\n",
      "Epoch 4/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1725\n",
      "Epoch 5/25\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1728\n",
      "Epoch 6/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1720\n",
      "Epoch 7/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1732\n",
      "Epoch 8/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1729\n",
      "Epoch 9/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1708A: 0s - loss: 0.1\n",
      "Epoch 10/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1737\n",
      "Epoch 11/25\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1718\n",
      "Epoch 12/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1729\n",
      "Epoch 13/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1729\n",
      "Epoch 14/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1732A: 0s - loss: 0.\n",
      "Epoch 15/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1722\n",
      "Epoch 16/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1748\n",
      "Epoch 17/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1740A: 2s - \n",
      "Epoch 18/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1746\n",
      "Epoch 19/25\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1733\n",
      "Epoch 20/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1726\n",
      "Epoch 21/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1720\n",
      "Epoch 22/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1698\n",
      "Epoch 23/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1743\n",
      "Epoch 24/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1735\n",
      "Epoch 25/25\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1727\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# generate data again\n",
    "obs = 10000\n",
    "xs = np.random.uniform(low=-8,high=8,size=(obs, 1))\n",
    "zs = np.random.uniform(-12, 12, (obs, 1))\n",
    "generated_inputs = np.column_stack(((xs,zs)))\n",
    "\n",
    "generated_targets = 12*xs - 6*zs # this is what the outcome looks like\n",
    "\n",
    "# save these files as an npz, so that I can then apply tf on things \n",
    "np.savez(\"TF_intro\", inputs=generated_inputs, targets=generated_targets) \n",
    "\n",
    "training_data = np.load(\"TF_intro.npz\")\n",
    "\n",
    "# unlike other packages, when employing tf we must actually build the model rather than just simply call it\n",
    "\n",
    "# incredibly simple, sequential model with only a single layer, initializing the weights/biases to zero at first\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1,kernel_initializer = 'zeros', bias_initializer = 'zeros')])\n",
    "\n",
    "# very simplified loss function (essentially MAD)\n",
    "def my_loss_fn(y_true, y_pred):\n",
    "    absolute_diff = tf.math.abs(y_true - y_pred)\n",
    "    return absolute_diff\n",
    "\n",
    "# use stoichastic gradient descent to optimize over time, apply the loss function\n",
    "model.compile(loss=my_loss_fn, optimizer='sgd')\n",
    "\n",
    "# see how it fits on the training data once the model has been compiled with loss/optimizer\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=25)\n",
    "\n",
    "# this shows how our data actually looks with the model, and it works!\n",
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data[\"targets\"]))\n",
    "\n",
    "plt.xlabel('inputs')\n",
    "plt.ylabel('outputs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Working on Audiobooks_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: code below comes from a Udemy tutorial... I did however write it all up and comment myself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load, balance, and shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing again...\n",
    "import numpy as np\n",
    "from sklearn import preprocessing # helpful to clean up data\n",
    "\n",
    "# import the csv file, seperate it by commas\n",
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1] #get all columns besides the first (customer ID, simply the identifier) and last one (outcome)\n",
    "targets_all = raw_csv_data[:, -1] # the target (outcome) is the last column\n",
    "\n",
    "# need to get an equal amount of 0's and 1's (balanced dataset)\n",
    "num_one_targets = int(np.sum(targets_all)) # number of ones\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "numtargets = targets_all.shape[0]\n",
    "\n",
    "for i in range(numtargets):\n",
    "    # if it is zero, then you need to increment the counter, and if we've reached the maximum amount of zeros, we need to remove\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets: \n",
    "            indices_to_remove.append(i) # removal enables balance\n",
    "\n",
    "# these new variables are the same as above but with removed indices to balance the data set\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)\n",
    "\n",
    "# standardize & shuffle data\n",
    "\n",
    "# standardize inputs\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)\n",
    "\n",
    "# shuffle data - it was originally arranged by date, which could be a confounding factor\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split dataset into test, train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# constants to fiddle around with\n",
    "percent_train = 0.8\n",
    "percent_test = 0.1\n",
    "\n",
    "train_samples_count = int(percent_train * samples_count)\n",
    "test_samples_count = int(percent_test * samples_count)\n",
    "validation_samples_count = samples_count - train_samples_count - test_samples_count\n",
    "\n",
    "# this gets the first x of each input/target to be train, next to be test, last to be validation\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count:train_samples_count+test_samples_count]\n",
    "test_targets = shuffled_targets[train_samples_count:train_samples_count+test_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count+test_samples_count:]\n",
    "validation_targets = shuffled_targets[train_samples_count+test_samples_count:]\n",
    "\n",
    "# Save up the train, validation, and test as npzs\n",
    "np.savez(\"Audiobooks_data_train\", inputs=train_inputs, targets=train_targets)\n",
    "np.savez(\"Audiobooks_data_test\", inputs=test_inputs, targets=test_targets)\n",
    "np.savez(\"Audiobooks_data_validation\", inputs=validation_inputs, targets=validation_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load in npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically pull train/validation/test back from the npz into inputs_targets we can run our Tensorflow model on\n",
    "npz = np.load(\"Audiobooks_data_train.npz\")\n",
    "train_inputs = npz[\"inputs\"].astype(np.float)\n",
    "train_targets = npz[\"targets\"].astype(np.int) # since the outcome is 0 or 1\n",
    "\n",
    "npz = np.load(\"Audiobooks_data_validation.npz\")\n",
    "validation_inputs = npz[\"inputs\"].astype(np.float)\n",
    "validation_targets = npz[\"targets\"].astype(np.int)\n",
    "\n",
    "npz = np.load(\"Audiobooks_data_test.npz\")\n",
    "test_inputs = npz[\"inputs\"].astype(np.float)\n",
    "test_targets = npz[\"targets\"].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 20\n",
    "\n",
    "# run a CNN with 2 hidden layers, activation is exponential linear unit, activation function is softmax since the targets are binary (0, 1), softmax always differentiable\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='elu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='elu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.5860 - accuracy: 0.7393\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3897 - accuracy: 0.8678\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3416 - accuracy: 0.8787\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.3219 - accuracy: 0.8829\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.3096 - accuracy: 0.8860\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.3013 - accuracy: 0.8877\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2944 - accuracy: 0.8913\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2881 - accuracy: 0.8905\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2834 - accuracy: 0.8947\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2788 - accuracy: 0.8958\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2756 - accuracy: 0.8969\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2719 - accuracy: 0.8975\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.2682 - accuracy: 0.8972\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2674 - accuracy: 0.8989\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2652 - accuracy: 0.8966\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2625 - accuracy: 0.8989\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2605 - accuracy: 0.8997\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2582 - accuracy: 0.9005\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2564 - accuracy: 0.9011\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.2554 - accuracy: 0.9011\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.2539 - accuracy: 0.9011\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.2529 - accuracy: 0.9019\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.2512 - accuracy: 0.9028\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.2502 - accuracy: 0.9042\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.2496 - accuracy: 0.9042\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.2490 - accuracy: 0.9036\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.2474 - accuracy: 0.9042\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.2464 - accuracy: 0.9047\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.2450 - accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.2448 - accuracy: 0.9078\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.2447 - accuracy: 0.9061\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.2441 - accuracy: 0.9067\n",
      "Epoch 33/100\n",
      "36/36 - 0s - loss: 0.2422 - accuracy: 0.9075\n",
      "Epoch 34/100\n",
      "36/36 - 0s - loss: 0.2423 - accuracy: 0.9086\n",
      "Epoch 35/100\n",
      "36/36 - 0s - loss: 0.2413 - accuracy: 0.9061\n",
      "Epoch 36/100\n",
      "36/36 - 0s - loss: 0.2405 - accuracy: 0.9086\n",
      "Epoch 37/100\n",
      "36/36 - 0s - loss: 0.2401 - accuracy: 0.9100\n",
      "Epoch 38/100\n",
      "36/36 - 0s - loss: 0.2395 - accuracy: 0.9086\n",
      "Epoch 39/100\n",
      "36/36 - 0s - loss: 0.2389 - accuracy: 0.9092\n",
      "Epoch 40/100\n",
      "36/36 - 0s - loss: 0.2381 - accuracy: 0.9103\n",
      "Epoch 41/100\n",
      "36/36 - 0s - loss: 0.2380 - accuracy: 0.9078\n",
      "Epoch 42/100\n",
      "36/36 - 0s - loss: 0.2374 - accuracy: 0.9117\n",
      "Epoch 43/100\n",
      "36/36 - 0s - loss: 0.2361 - accuracy: 0.9106\n",
      "Epoch 44/100\n",
      "36/36 - 0s - loss: 0.2353 - accuracy: 0.9111\n",
      "Epoch 45/100\n",
      "36/36 - 0s - loss: 0.2360 - accuracy: 0.9134\n",
      "Epoch 46/100\n",
      "36/36 - 0s - loss: 0.2374 - accuracy: 0.9114\n",
      "Epoch 47/100\n",
      "36/36 - 0s - loss: 0.2358 - accuracy: 0.9109\n",
      "Epoch 48/100\n",
      "36/36 - 0s - loss: 0.2344 - accuracy: 0.9114\n",
      "Epoch 49/100\n",
      "36/36 - 0s - loss: 0.2337 - accuracy: 0.9114\n",
      "Epoch 50/100\n",
      "36/36 - 0s - loss: 0.2335 - accuracy: 0.9139\n",
      "Epoch 51/100\n",
      "36/36 - 0s - loss: 0.2336 - accuracy: 0.9131\n",
      "Epoch 52/100\n",
      "36/36 - 0s - loss: 0.2344 - accuracy: 0.9128\n",
      "Epoch 53/100\n",
      "36/36 - 0s - loss: 0.2318 - accuracy: 0.9123\n",
      "Epoch 54/100\n",
      "36/36 - 0s - loss: 0.2331 - accuracy: 0.9131\n",
      "Epoch 55/100\n",
      "36/36 - 0s - loss: 0.2311 - accuracy: 0.9145\n",
      "Epoch 56/100\n",
      "36/36 - 0s - loss: 0.2326 - accuracy: 0.9137\n",
      "Epoch 57/100\n",
      "36/36 - 0s - loss: 0.2315 - accuracy: 0.9142\n",
      "Epoch 58/100\n",
      "36/36 - 0s - loss: 0.2298 - accuracy: 0.9139\n",
      "Epoch 59/100\n",
      "36/36 - 0s - loss: 0.2312 - accuracy: 0.9131\n",
      "Epoch 60/100\n",
      "36/36 - 0s - loss: 0.2312 - accuracy: 0.9137\n",
      "Epoch 61/100\n",
      "36/36 - 0s - loss: 0.2310 - accuracy: 0.9134\n",
      "Epoch 62/100\n",
      "36/36 - 0s - loss: 0.2309 - accuracy: 0.9145\n",
      "Epoch 63/100\n",
      "36/36 - 0s - loss: 0.2297 - accuracy: 0.9131\n",
      "Epoch 64/100\n",
      "36/36 - 0s - loss: 0.2304 - accuracy: 0.9134\n",
      "Epoch 65/100\n",
      "36/36 - 0s - loss: 0.2299 - accuracy: 0.9142\n",
      "Epoch 66/100\n",
      "36/36 - 0s - loss: 0.2287 - accuracy: 0.9151\n",
      "Epoch 67/100\n",
      "36/36 - 0s - loss: 0.2288 - accuracy: 0.9117\n",
      "Epoch 68/100\n",
      "36/36 - 0s - loss: 0.2282 - accuracy: 0.9145\n",
      "Epoch 69/100\n",
      "36/36 - 0s - loss: 0.2307 - accuracy: 0.9139\n",
      "Epoch 70/100\n",
      "36/36 - 0s - loss: 0.2280 - accuracy: 0.9145\n",
      "Epoch 71/100\n",
      "36/36 - 0s - loss: 0.2281 - accuracy: 0.9148\n",
      "Epoch 72/100\n",
      "36/36 - 0s - loss: 0.2288 - accuracy: 0.9120\n",
      "Epoch 73/100\n",
      "36/36 - 0s - loss: 0.2283 - accuracy: 0.9148\n",
      "Epoch 74/100\n",
      "36/36 - 0s - loss: 0.2267 - accuracy: 0.9145\n",
      "Epoch 75/100\n",
      "36/36 - 0s - loss: 0.2266 - accuracy: 0.9139\n",
      "Epoch 76/100\n",
      "36/36 - 0s - loss: 0.2275 - accuracy: 0.9139\n",
      "Epoch 77/100\n",
      "36/36 - 0s - loss: 0.2261 - accuracy: 0.9137\n",
      "Epoch 78/100\n",
      "36/36 - 0s - loss: 0.2255 - accuracy: 0.9151\n",
      "Epoch 79/100\n",
      "36/36 - 0s - loss: 0.2250 - accuracy: 0.9151\n",
      "Epoch 80/100\n",
      "36/36 - 0s - loss: 0.2263 - accuracy: 0.9134\n",
      "Epoch 81/100\n",
      "36/36 - 0s - loss: 0.2255 - accuracy: 0.9137\n",
      "Epoch 82/100\n",
      "36/36 - 0s - loss: 0.2274 - accuracy: 0.9148\n",
      "Epoch 83/100\n",
      "36/36 - 0s - loss: 0.2259 - accuracy: 0.9145\n",
      "Epoch 84/100\n",
      "36/36 - 0s - loss: 0.2256 - accuracy: 0.9156\n",
      "Epoch 85/100\n",
      "36/36 - 0s - loss: 0.2239 - accuracy: 0.9151\n",
      "Epoch 86/100\n",
      "36/36 - 0s - loss: 0.2258 - accuracy: 0.9134\n",
      "Epoch 87/100\n",
      "36/36 - 0s - loss: 0.2244 - accuracy: 0.9159\n",
      "Epoch 88/100\n",
      "36/36 - 0s - loss: 0.2257 - accuracy: 0.9148\n",
      "Epoch 89/100\n",
      "36/36 - 0s - loss: 0.2262 - accuracy: 0.9142\n",
      "Epoch 90/100\n",
      "36/36 - 0s - loss: 0.2262 - accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "36/36 - 0s - loss: 0.2256 - accuracy: 0.9142\n",
      "Epoch 92/100\n",
      "36/36 - 0s - loss: 0.2243 - accuracy: 0.9148\n",
      "Epoch 93/100\n",
      "36/36 - 0s - loss: 0.2227 - accuracy: 0.9148\n",
      "Epoch 94/100\n",
      "36/36 - 0s - loss: 0.2241 - accuracy: 0.9145\n",
      "Epoch 95/100\n",
      "36/36 - 0s - loss: 0.2242 - accuracy: 0.9151\n",
      "Epoch 96/100\n",
      "36/36 - 0s - loss: 0.2246 - accuracy: 0.9151\n",
      "Epoch 97/100\n",
      "36/36 - 0s - loss: 0.2237 - accuracy: 0.9145\n",
      "Epoch 98/100\n",
      "36/36 - 0s - loss: 0.2234 - accuracy: 0.9148\n",
      "Epoch 99/100\n",
      "36/36 - 0s - loss: 0.2237 - accuracy: 0.9162\n",
      "Epoch 100/100\n",
      "36/36 - 0s - loss: 0.2232 - accuracy: 0.9153\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9306\n",
      "this is test loss: 0.20386266708374023\n",
      "this is test accuracy: 0.9306487441062927\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size = batch_size, \n",
    "          epochs = max_epochs, # number of times to run the model\n",
    "          verbose=2) # how much progress do we show\n",
    "\n",
    "# test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "\n",
    "print (\"this is test loss: \" + str(test_loss) + \"\\n\" + \"this is test accuracy: \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Working on MNIST (handwritten digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is the \"hello world\" of Machine Learning. It is a file of 70k handwritten digits, where each image is 28x28 pixels, and the input vale of each pixel is 0-255 where 0 is black and 255 is white.\n",
    "\n",
    "We will be running a deep neural network with 3 hidden layers, and 10 output units (0 to 9 is the answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import revelent libraries & split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# load data\n",
    "mnist_data, mnist_info = tfds.load(name=\"mnist\", with_info=True, as_supervised = True)\n",
    "# split\n",
    "mnist_train = mnist_data[\"train\"]\n",
    "mnist_test = mnist_data[\"test\"]\n",
    "\n",
    "# get validation\n",
    "VALIDATION_PERCENT = 0.1\n",
    "\n",
    "num_validation = VALIDATION_PERCENT * mnist_info.splits[\"train\"].num_examples\n",
    "num_validation = tf.cast(num_validation, tf.int64)\n",
    "num_test = mnist_info.splits[\"test\"].num_examples\n",
    "num_test = tf.cast(num_test, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    return (image/255), label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shuffle and batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000 #dealing w/ enormous datasets, can't shuffle it all at once!\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation)\n",
    "test_data = test_data.batch(num_test)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outline and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 9s - loss: 0.4497 - accuracy: 0.8665 - val_loss: 0.2198 - val_accuracy: 0.9317\n",
      "Epoch 2/5\n",
      "540/540 - 7s - loss: 0.1949 - accuracy: 0.9430 - val_loss: 0.1682 - val_accuracy: 0.9473\n",
      "Epoch 3/5\n",
      "540/540 - 5s - loss: 0.1516 - accuracy: 0.9548 - val_loss: 0.1477 - val_accuracy: 0.9547\n",
      "Epoch 4/5\n",
      "540/540 - 5s - loss: 0.1249 - accuracy: 0.9637 - val_loss: 0.1131 - val_accuracy: 0.9663\n",
      "Epoch 5/5\n",
      "540/540 - 5s - loss: 0.1092 - accuracy: 0.9671 - val_loss: 0.1075 - val_accuracy: 0.9650\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9635\n",
      "this is test loss: 0.1259012222290039\n",
      "this is test accuracy: 0.9635000228881836\n"
     ]
    }
   ],
   "source": [
    "# Outline model\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 40\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])\n",
    "# choose optimizer and the loss function\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs, validation_targets), verbose=2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print (\"this is test loss: \" + str(test_loss) + \"\\n\" + \"this is test accuracy: \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
